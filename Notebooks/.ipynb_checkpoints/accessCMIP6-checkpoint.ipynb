{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Coupled Model Intercomparison Project (CMIP)\n",
    "This notebook uses google cloud file storage to access model outputs for the CMIP6 data. The packages below are needed to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cftime\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from operator import itemgetter # For list subsetting but this is idiotic\n",
    "import intake\n",
    "import gcsfs\n",
    "import os\n",
    "import warnings \n",
    "import xagg as xa\n",
    "import dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Experiments, Variables, and Times\n",
    "We are going to pull down data for this historical simulations, and SSPs 2.6, 4.5, and 8.5. Our variable is \"tas\" which stands for \"temperature of air at the surface.\" For historical we pull down 1985-2014 and we pull down all the data from 2020-2100 for the simulations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params_all = [{'experiment_id':'historical','table_id':'day','variable_id':'tas','member_id':'r1i1p1f1'},\n",
    "                   {'experiment_id':'ssp126','table_id':'day','variable_id':'tas','member_id':'r1i1p1f1'},\n",
    "                   {'experiment_id':'ssp245','table_id':'day','variable_id':'tas','member_id':'r1i1p1f1'},\n",
    "                   {'experiment_id':'ssp585','table_id':'day','variable_id':'tas','member_id':'r1i1p1f1'}]\n",
    "subset_params = {'lat':[28,32],'lon':[-92,-88],\n",
    "                  'time':{'historical':['1985-01-01','2014-12-31'],\n",
    "                          'ssp126':['2020-01-01','2100-12-31'],\n",
    "                          'ssp245':['2020-01-01','2100-12-31'],\n",
    "                          'ssp585':['2020-01-01','2100-12-31']}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Google Cloud Storage access\n",
    "This code gets us a key to access the files and generates a table with metadata for the experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access google cloud storage links\n",
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only')\n",
    "# Get info about CMIP6 datasets\n",
    "cmip6_datasets = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = data_params_all[0]\n",
    "cmip6_sub = cmip6_datasets.query(' and '.join([k+\" == '\"+data_params[k]+\"'\" \n",
    "                                               for k in data_params.keys() \n",
    "                                               if k != 'other']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7fa67a5cc9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set({\"array.slicing.split_large_chunks\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Data\n",
    "Warning: This block takes a couple minutes to run. There will be a lot of stuff printed in the notebook and some warnings thrown, but don't worry about them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0811372fade475f80259c96062cc06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing GFDL-CM4!\n",
      "GFDL-CM4 processed!\n",
      "processing GFDL-CM4!\n",
      "GFDL-CM4 processed!\n",
      "processing BCC-CSM2-MR!\n",
      "BCC-CSM2-MR processed!\n",
      "processing AWI-CM-1-1-MR!\n",
      "AWI-CM-1-1-MR processed!\n",
      "processing BCC-ESM1!\n",
      "BCC-ESM1 processed!\n",
      "processing CESM2-WACCM!\n",
      "CESM2-WACCM processed!\n",
      "processing CESM2!\n",
      "CESM2 processed!\n",
      "processing SAM0-UNICON!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/558_c385167_rhq6m2ykzd_40000gn/T/ipykernel_23173/2366600646.py:53: UserWarning: Model SAM0-UNICON has an unsorted time dimension.\n",
      "  warnings.warn('Model '+ds.source_id+' has an unsorted time dimension.')\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/core/indexing.py:1227: PerformanceWarning: Slicing with an out-of-order index is generating 304 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM0-UNICON processed!\n",
      "processing CanESM5!\n",
      "CanESM5 processed!\n",
      "processing INM-CM4-8!\n",
      "INM-CM4-8 processed!\n",
      "processing MRI-ESM2-0!\n",
      "MRI-ESM2-0 processed!\n",
      "processing INM-CM5-0!\n",
      "INM-CM5-0 processed!\n",
      "processing IPSL-CM6A-LR!\n",
      "IPSL-CM6A-LR processed!\n",
      "processing MPI-ESM-1-2-HAM!\n",
      "MPI-ESM-1-2-HAM processed!\n",
      "processing MPI-ESM1-2-LR!\n",
      "MPI-ESM1-2-LR processed!\n",
      "processing MPI-ESM1-2-HR!\n",
      "MPI-ESM1-2-HR processed!\n",
      "processing GFDL-ESM4!\n",
      "GFDL-ESM4 processed!\n",
      "processing NESM3!\n",
      "NESM3 processed!\n",
      "processing NorESM2-LM!\n",
      "NorESM2-LM processed!\n",
      "processing FGOALS-g3!\n",
      "FGOALS-g3 processed!\n",
      "processing MIROC6!\n",
      "MIROC6 processed!\n",
      "processing FGOALS-f3-L!\n",
      "FGOALS-f3-L processed!\n",
      "processing ACCESS-CM2!\n",
      "ACCESS-CM2 processed!\n",
      "processing NorESM2-MM!\n",
      "NorESM2-MM processed!\n",
      "processing ACCESS-ESM1-5!\n",
      "ACCESS-ESM1-5 processed!\n",
      "processing CESM2-WACCM-FV2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/558_c385167_rhq6m2ykzd_40000gn/T/ipykernel_23173/2366600646.py:53: UserWarning: Model CESM2-WACCM-FV2 has an unsorted time dimension.\n",
      "  warnings.warn('Model '+ds.source_id+' has an unsorted time dimension.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESM2-WACCM-FV2 processed!\n",
      "processing CESM2-FV2!\n",
      "CESM2-FV2 processed!\n",
      "processing KIOST-ESM!\n",
      "KIOST-ESM processed!\n",
      "processing IITM-ESM!\n",
      "IITM-ESM processed!\n",
      "processing AWI-ESM-1-1-LR!\n",
      "AWI-ESM-1-1-LR processed!\n",
      "processing EC-Earth3-Veg-LR!\n",
      "EC-Earth3-Veg-LR processed!\n",
      "processing EC-Earth3-Veg!\n",
      "EC-Earth3-Veg processed!\n",
      "processing EC-Earth3!\n",
      "EC-Earth3 processed!\n",
      "processing KACE-1-0-G!\n",
      "KACE-1-0-G processed!\n",
      "processing CMCC-CM2-SR5!\n",
      "CMCC-CM2-SR5 processed!\n",
      "processing EC-Earth3-AerChem!\n",
      "EC-Earth3-AerChem processed!\n",
      "processing TaiESM1!\n",
      "TaiESM1 processed!\n",
      "processing NorCPM1!\n",
      "NorCPM1 processed!\n",
      "processing IPSL-CM5A2-INCA!\n",
      "IPSL-CM5A2-INCA processed!\n",
      "processing CMCC-CM2-HR4!\n",
      "CMCC-CM2-HR4 processed!\n",
      "processing EC-Earth3-CC!\n",
      "EC-Earth3-CC processed!\n",
      "processing CMCC-ESM2!\n",
      "CMCC-ESM2 processed!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9ecfd63dd648fbba29e0aaa547d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing GFDL-ESM4!\n",
      "GFDL-ESM4 processed!\n",
      "processing BCC-CSM2-MR!\n",
      "BCC-CSM2-MR processed!\n",
      "processing CanESM5!\n",
      "issue with model '+mod+' (if it's CESM2-WACCM it's probably because the wrong file was downloaded)\n",
      "CanESM5 processed!\n",
      "processing AWI-CM-1-1-MR!\n",
      "AWI-CM-1-1-MR processed!\n",
      "processing INM-CM4-8!\n",
      "INM-CM4-8 processed!\n",
      "processing INM-CM5-0!\n",
      "INM-CM5-0 processed!\n",
      "processing MPI-ESM1-2-HR!\n",
      "MPI-ESM1-2-HR processed!\n",
      "processing MPI-ESM1-2-LR!\n",
      "MPI-ESM1-2-LR processed!\n",
      "processing NESM3!\n",
      "NESM3 processed!\n",
      "processing FGOALS-g3!\n",
      "FGOALS-g3 processed!\n",
      "processing IPSL-CM6A-LR!\n",
      "IPSL-CM6A-LR processed!\n",
      "processing MIROC6!\n",
      "MIROC6 processed!\n",
      "processing MRI-ESM2-0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/core/indexing.py:422: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(array[self.key], dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0 processed!\n",
      "processing ACCESS-CM2!\n",
      "ACCESS-CM2 processed!\n",
      "processing NorESM2-MM!\n",
      "NorESM2-MM processed!\n",
      "processing KIOST-ESM!\n",
      "KIOST-ESM processed!\n",
      "processing EC-Earth3-Veg!\n",
      "EC-Earth3-Veg processed!\n",
      "processing EC-Earth3!\n",
      "EC-Earth3 processed!\n",
      "processing KACE-1-0-G!\n",
      "KACE-1-0-G processed!\n",
      "processing CMCC-CM2-SR5!\n",
      "CMCC-CM2-SR5 processed!\n",
      "processing IITM-ESM!\n",
      "IITM-ESM processed!\n",
      "processing EC-Earth3-Veg-LR!\n",
      "EC-Earth3-Veg-LR processed!\n",
      "processing IPSL-CM5A2-INCA!\n",
      "IPSL-CM5A2-INCA processed!\n",
      "processing CMCC-ESM2!\n",
      "CMCC-ESM2 processed!\n",
      "processing CESM2-WACCM!\n",
      "CESM2-WACCM processed!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c7cfb7a32406ea211769849873125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing GFDL-CM4!\n",
      "GFDL-CM4 processed!\n",
      "processing GFDL-CM4!\n",
      "GFDL-CM4 processed!\n",
      "processing GFDL-ESM4!\n",
      "GFDL-ESM4 processed!\n",
      "processing BCC-CSM2-MR!\n",
      "BCC-CSM2-MR processed!\n",
      "processing CanESM5!\n",
      "CanESM5 processed!\n",
      "processing AWI-CM-1-1-MR!\n",
      "AWI-CM-1-1-MR processed!\n",
      "processing MRI-ESM2-0!\n",
      "MRI-ESM2-0 processed!\n",
      "processing INM-CM4-8!\n",
      "INM-CM4-8 processed!\n",
      "processing IPSL-CM6A-LR!\n",
      "IPSL-CM6A-LR processed!\n",
      "processing INM-CM5-0!\n",
      "INM-CM5-0 processed!\n",
      "processing MPI-ESM1-2-LR!\n",
      "MPI-ESM1-2-LR processed!\n",
      "processing MPI-ESM1-2-HR!\n",
      "MPI-ESM1-2-HR processed!\n",
      "processing NESM3!\n",
      "NESM3 processed!\n",
      "processing CESM2-WACCM!\n",
      "CESM2-WACCM processed!\n",
      "processing FGOALS-g3!\n",
      "FGOALS-g3 processed!\n",
      "processing MIROC6!\n",
      "MIROC6 processed!\n",
      "processing NorESM2-LM!\n",
      "NorESM2-LM processed!\n",
      "processing ACCESS-CM2!\n",
      "ACCESS-CM2 processed!\n",
      "processing NorESM2-MM!\n",
      "NorESM2-MM processed!\n",
      "processing KIOST-ESM!\n",
      "KIOST-ESM processed!\n",
      "processing EC-Earth3-Veg!\n",
      "EC-Earth3-Veg processed!\n",
      "processing EC-Earth3!\n",
      "EC-Earth3 processed!\n",
      "processing KACE-1-0-G!\n",
      "KACE-1-0-G processed!\n",
      "processing CMCC-CM2-SR5!\n",
      "CMCC-CM2-SR5 processed!\n",
      "processing IITM-ESM!\n",
      "IITM-ESM processed!\n",
      "processing EC-Earth3-Veg-LR!\n",
      "EC-Earth3-Veg-LR processed!\n",
      "processing EC-Earth3-CC!\n",
      "EC-Earth3-CC processed!\n",
      "processing CMCC-ESM2!\n",
      "CMCC-ESM2 processed!\n",
      "processing TaiESM1!\n",
      "TaiESM1 processed!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5847f164bdac4833a7b0c1a320d90f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing GFDL-CM4!\n",
      "GFDL-CM4 processed!\n",
      "processing GFDL-CM4!\n",
      "GFDL-CM4 processed!\n",
      "processing GFDL-ESM4!\n",
      "GFDL-ESM4 processed!\n",
      "processing BCC-CSM2-MR!\n",
      "BCC-CSM2-MR processed!\n",
      "processing CanESM5!\n",
      "CanESM5 processed!\n",
      "processing AWI-CM-1-1-MR!\n",
      "AWI-CM-1-1-MR processed!\n",
      "processing INM-CM4-8!\n",
      "INM-CM4-8 processed!\n",
      "processing MPI-ESM1-2-LR!\n",
      "MPI-ESM1-2-LR processed!\n",
      "processing MPI-ESM1-2-HR!\n",
      "MPI-ESM1-2-HR processed!\n",
      "processing INM-CM5-0!\n",
      "INM-CM5-0 processed!\n",
      "processing NESM3!\n",
      "NESM3 processed!\n",
      "processing FGOALS-g3!\n",
      "FGOALS-g3 processed!\n",
      "processing IPSL-CM6A-LR!\n",
      "IPSL-CM6A-LR processed!\n",
      "processing KACE-1-0-G!\n",
      "KACE-1-0-G processed!\n",
      "processing MIROC6!\n",
      "MIROC6 processed!\n",
      "processing MRI-ESM2-0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/core/indexing.py:422: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(array[self.key], dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0 processed!\n",
      "processing NorESM2-MM!\n",
      "NorESM2-MM processed!\n",
      "processing NorESM2-LM!\n",
      "NorESM2-LM processed!\n",
      "processing KIOST-ESM!\n",
      "KIOST-ESM processed!\n",
      "processing EC-Earth3-Veg!\n",
      "EC-Earth3-Veg processed!\n",
      "processing EC-Earth3!\n",
      "EC-Earth3 processed!\n",
      "processing CMCC-CM2-SR5!\n",
      "CMCC-CM2-SR5 processed!\n",
      "processing CESM2-WACCM!\n",
      "CESM2-WACCM processed!\n",
      "processing TaiESM1!\n",
      "TaiESM1 processed!\n",
      "processing IITM-ESM!\n",
      "IITM-ESM processed!\n",
      "processing EC-Earth3-Veg-LR!\n",
      "EC-Earth3-Veg-LR processed!\n",
      "processing EC-Earth3-CC!\n",
      "EC-Earth3-CC processed!\n",
      "processing CMCC-ESM2!\n",
      "CMCC-ESM2 processed!\n",
      "processing ACCESS-CM2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/core/indexing.py:422: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(array[self.key], dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue with model '+mod+' (if it's CESM2-WACCM it's probably because the wrong file was downloaded)\n",
      "ACCESS-CM2 processed!\n",
      "processing ACCESS-ESM1-5!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/coding/times.py:526: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/Users/danielbabin/opt/miniconda3/envs/geospatial/lib/python3.8/site-packages/xarray/core/indexing.py:422: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(array[self.key], dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 processed!\n"
     ]
    }
   ],
   "source": [
    "remove_leaps = True\n",
    "#------ Process by variable and dataset in the subset ------\n",
    "dss_out = dict()\n",
    "for data_params in data_params_all:\n",
    "    dss_out[data_params['experiment_id']] = dict()\n",
    "    # Get subset based on the data params above, now just for this one variable\n",
    "    cmip6_sub = cmip6_datasets.query(' and '.join([k+\" == '\"+data_params[k]+\"'\" \n",
    "                                                   for k in data_params.keys() \n",
    "                                                   if k != 'other']))\n",
    "        \n",
    "    for url in tqdm(cmip6_sub.zstore.values):\n",
    "        mod = re.split('\\/',url)[6]\n",
    "        print('processing '+mod+'!')\n",
    "        \n",
    "        \n",
    "        # Open dataset\n",
    "        ds = xr.open_zarr(fs.get_mapper(url),consolidated=True)\n",
    "\n",
    "        # Rename to lat / lon (let's hope there's no \n",
    "        # Latitude / latitude_1 / etc. in this dataset)\n",
    "        try:\n",
    "            ds = ds.rename({'longitude':'lon','latitude':'lat'})\n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "        # same with 'nav_lat' and 'nav_lon' ???\n",
    "        try:\n",
    "            ds = ds.rename({'nav_lon':'lon','nav_lat':'lat'})\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "        \n",
    "        # Fix coordinate doubling (this was an issue in NorCPM1, \n",
    "        # where thankfully the values of the variables were nans,\n",
    "        # though I still don't know how this happened - some lat\n",
    "        # values were doubled within floating point errors)\n",
    "        if 'lat' in ds[data_params['variable_id']].dims:\n",
    "            if len(np.unique(np.round(ds.lat.values,10))) != ds.dims['lat']:\n",
    "                ds = (ds.isel(lat=(~np.isnan(ds.isel(lon=1,time=1)\n",
    "                                             [data_params['variable_id']].values)).nonzero()[0],drop=True))\n",
    "                warnings.warn('Model '+ds.source_id+' has duplicate lat values; attempting to compensate by '+\n",
    "                              'dropping lat values that are nan in the main variable in the first timestep')\n",
    "            if len(np.unique(np.round(ds.lon.values,10))) != ds.dims['lon']:\n",
    "                ds = (ds.isel(lon=(~np.isnan(ds.isel(lat=1,time=1)\n",
    "                                             [data_params['variable_id']].values)).nonzero()[0],drop=True))\n",
    "                warnings.warn('Model '+ds.source_id+' has duplicate lon values; attempting to compensate by '+\n",
    "                              'dropping lon values that are nan in the main variable in the first timestep')\n",
    "\n",
    "        # Sort by time, if not sorted (this happened with\n",
    "        # a model; keeping a warning, cuz this seems weird)\n",
    "        if 'time' in subset_params:\n",
    "            if (ds.time.values != np.sort(ds.time)).any():\n",
    "                warnings.warn('Model '+ds.source_id+' has an unsorted time dimension.')\n",
    "                ds = ds.sortby('time')\n",
    "            \n",
    "        # Now, save by the subsets desired in subset_params_all above\n",
    "        ds_tmp = xa.fix_ds(ds)\n",
    "        # Subset by time as set in subset_params\n",
    "        if 'time' in subset_params:\n",
    "            if (ds.time.max().dt.day==30) | (type(ds.time.values[0]) == cftime._cftime.Datetime360Day): \n",
    "                # (If it's a 360-day calendar, then subsetting to \"12-31\"\n",
    "                # will throw an error; this switches that call to \"12-30\")\n",
    "                # Also checking explicitly for 360day calendar; some monthly \n",
    "                # data is still shown as 360-day even when it's monthly, and will\n",
    "                # fail on date ranges with date 31 in a month\n",
    "                ds_tmp = (ds_tmp.sel(time=slice(subset_params['time'][data_params['experiment_id']][0],\n",
    "                                        re.sub('-31','-30',subset_params['time'][data_params['experiment_id']][1]))))\n",
    "            else:\n",
    "                ds_tmp = (ds_tmp.sel(time=slice(*subset_params['time'][data_params['experiment_id']])))\n",
    "                \n",
    "        # REMOVE 366th DAY OF LEAP YEARS\n",
    "        if remove_leaps:\n",
    "            try:\n",
    "                ds_tmp = ds_tmp.isel(time=(ds_tmp.time.dt.dayofyear<366))\n",
    "            except:\n",
    "                print(\"issue with model '+mod+' (if it's CESM2-WACCM it's probably because the wrong file was downloaded)\")\n",
    "\n",
    "        # Subset by space as set in subset_params\n",
    "        if 'lat' in subset_params.keys():\n",
    "            if not 'lat' in ds[data_params['variable_id']].dims:\n",
    "                ds_tmp = ds_tmp.where((ds_tmp.lat >= subset_params['lat'][0]) & (ds_tmp.lat <= subset_params['lat'][1]) &\n",
    "                 (ds_tmp.lon >= subset_params['lon'][0]) & (ds_tmp.lon <= subset_params['lon'][1]),drop=True)\n",
    "            else:\n",
    "                ds_tmp = (ds_tmp.sel(lat=slice(*subset_params['lat']),\n",
    "                                     lon=slice(*subset_params['lon'])))\n",
    "\n",
    "        # Output\n",
    "        dss_out[data_params['experiment_id']][mod] = ds_tmp\n",
    "\n",
    "        # Status update\n",
    "        print(mod+' processed!')\n",
    "        \n",
    "        del ds, ds_tmp\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset to Closest Pixel to New Orleans\n",
    "This block does some geospatial slicing to get the pixel for new orleans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in dss_out:\n",
    "    for mod in dss_out[exp]:\n",
    "        dss_out[exp][mod] = dss_out[exp][mod].isel(lat=np.abs(dss_out[exp][mod].lat-30).argmin(),\n",
    "                                                    lon=np.abs(dss_out[exp][mod].lon-(-90)).argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Simulations\n",
    "At the moment, everything has been loaded lazily using dask. That basically means that the computer knows where to look to get the data and what to do with it, but hasn't done it yet. Running the .compute() operation on a dask object will load the data and get some real numbers. But because the volume of data is so large, this will take a few hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSP5 8.5\n",
    "SSP585 is a scenario which we do not mitigate greenhouse gasses at all. It's also called \"Business as usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=list(dss_out['ssp585'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL-CM4\n",
      "GFDL-ESM4\n",
      "BCC-CSM2-MR\n",
      "CanESM5\n",
      "AWI-CM-1-1-MR\n",
      "INM-CM4-8\n",
      "MPI-ESM1-2-LR\n",
      "MPI-ESM1-2-HR\n",
      "INM-CM5-0\n",
      "NESM3\n",
      "FGOALS-g3\n",
      "IPSL-CM6A-LR\n",
      "KACE-1-0-G\n",
      "MIROC6\n",
      "MRI-ESM2-0\n",
      "NorESM2-MM\n",
      "NorESM2-LM\n",
      "KIOST-ESM\n",
      "EC-Earth3-Veg\n",
      "EC-Earth3\n",
      "CMCC-CM2-SR5\n",
      "CESM2-WACCM\n",
      "TaiESM1\n",
      "IITM-ESM\n",
      "EC-Earth3-Veg-LR\n",
      "EC-Earth3-CC\n",
      "CMCC-ESM2\n",
      "ACCESS-CM2\n",
      "ACCESS-ESM1-5\n"
     ]
    }
   ],
   "source": [
    "ssp585_eoc={}\n",
    "for key in keys:\n",
    "    ssp585_eoc[key]=dss_out['ssp585'][key]['tas'].compute()\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSP2 4.5\n",
    "SSP245 is the middle of the road scenario, where we invest a minimum effort to curb emissions. We are basically on this path at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=list(dss_out['ssp245'].keys())\n",
    "keys.remove('KACE-1-0-G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC-Earth3-CC\n",
      "CMCC-ESM2\n",
      "TaiESM1\n"
     ]
    }
   ],
   "source": [
    "# ssp245_eoc={}\n",
    "for key in keys[-3:]:\n",
    "    ssp245_eoc[key]=dss_out['ssp245'][key]['tas'].compute()\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSP1 2.6\n",
    "This represents aggressive action to curb emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=list(dss_out['ssp126'].keys())\n",
    "keys.remove('KACE-1-0-G')\n",
    "keys.remove('ACCESS-CM2')\n",
    "keys.remove('KIOST-ESM')\n",
    "keys.remove('CESM2-WACCM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL-ESM4\n",
      "BCC-CSM2-MR\n",
      "CanESM5\n",
      "AWI-CM-1-1-MR\n",
      "INM-CM4-8\n",
      "INM-CM5-0\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR\n",
      "NESM3\n",
      "FGOALS-g3\n",
      "IPSL-CM6A-LR\n",
      "MIROC6\n",
      "MRI-ESM2-0\n",
      "NorESM2-MM\n",
      "EC-Earth3-Veg\n",
      "EC-Earth3\n",
      "CMCC-CM2-SR5\n",
      "IITM-ESM\n",
      "EC-Earth3-Veg-LR\n",
      "IPSL-CM5A2-INCA\n",
      "CMCC-ESM2\n"
     ]
    }
   ],
   "source": [
    "ssp126_eoc={}\n",
    "for key in keys:\n",
    "    ssp126_eoc[key]=dss_out['ssp126'][key]['tas'].compute()\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical\n",
    "It's necessary to draw down historical data for our projections. For each simulation, you get a temperature difference from the models historical value, representing a temperature change. This is preferred to literally interpretting temperatures from the model output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=list(dss_out['historical'].keys())\n",
    "keys.remove('KACE-1-0-G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL-CM4\n",
      "BCC-CSM2-MR\n",
      "AWI-CM-1-1-MR\n",
      "BCC-ESM1\n",
      "CESM2-WACCM\n",
      "CESM2\n",
      "SAM0-UNICON\n",
      "CanESM5\n",
      "INM-CM4-8\n",
      "MRI-ESM2-0\n",
      "INM-CM5-0\n",
      "IPSL-CM6A-LR\n",
      "MPI-ESM-1-2-HAM\n",
      "MPI-ESM1-2-LR\n",
      "MPI-ESM1-2-HR\n",
      "GFDL-ESM4\n",
      "NESM3\n",
      "NorESM2-LM\n",
      "FGOALS-g3\n",
      "MIROC6\n",
      "FGOALS-f3-L\n",
      "ACCESS-CM2\n",
      "NorESM2-MM\n",
      "ACCESS-ESM1-5\n",
      "CESM2-WACCM-FV2\n",
      "CESM2-FV2\n",
      "KIOST-ESM\n",
      "IITM-ESM\n",
      "AWI-ESM-1-1-LR\n",
      "EC-Earth3-Veg-LR\n",
      "EC-Earth3-Veg\n",
      "EC-Earth3\n",
      "CMCC-CM2-SR5\n",
      "EC-Earth3-AerChem\n",
      "TaiESM1\n",
      "NorCPM1\n",
      "IPSL-CM5A2-INCA\n",
      "CMCC-CM2-HR4\n",
      "EC-Earth3-CC\n",
      "CMCC-ESM2\n"
     ]
    }
   ],
   "source": [
    "historical={}\n",
    "for key in keys:\n",
    "    historical[key]=dss_out['historical'][key]['tas'].compute()\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure and Export\n",
    "This code restructures these dask/x-array objects into a simple table and exports them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes={}\n",
    "scenarios_keys=['historical','ssp585','ssp245','ssp126']\n",
    "scenarios_data={'historical':historical,\n",
    "                'ssp585':ssp585_eoc,\n",
    "                'ssp245':ssp245_eoc,\n",
    "                'ssp126':ssp126_eoc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path='/Users/danielbabin/GitHub/LouisianaWinters/Data/SSPs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/558_c385167_rhq6m2ykzd_40000gn/T/ipykernel_23173/2231930991.py:9: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  dataframes[scen]['date']=dataframes[scen].index.to_datetimeindex()\n"
     ]
    }
   ],
   "source": [
    "for scen in scenarios_keys:\n",
    "    experiments=list(scenarios_data[scen].keys())\n",
    "    dataframes[scen]=scenarios_data[scen][experiments[0]].to_dataframe()\n",
    "    dataframes[scen].rename(columns={'tasmax':experiments[0]})\n",
    "    for exp in scenarios_data[scen].keys():\n",
    "        values=scenarios_data[scen][exp].values\n",
    "        if len(values)==len(dataframes[scen]):\n",
    "            dataframes[scen][exp]=scenarios_data[scen][exp].values\n",
    "    dataframes[scen]['date']=dataframes[scen].index.to_datetimeindex()\n",
    "    dataframes[scen]=dataframes[scen].set_index('date')\n",
    "    dataframes[scen].to_csv(out_path+scen+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
